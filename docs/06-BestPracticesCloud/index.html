<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.fd17476c3">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="THE DATA ENGINEERING COOKBOOK Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="THE DATA ENGINEERING COOKBOOK Blog Atom Feed"><title data-react-helmet="true">06-BestPracticesCloud | THE DATA ENGINEERING COOKBOOK</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="06-BestPracticesCloud | THE DATA ENGINEERING COOKBOOK"><meta data-react-helmet="true" name="description" content="Best Practices Cloud Platforms"><meta data-react-helmet="true" property="og:description" content="Best Practices Cloud Platforms"><meta data-react-helmet="true" property="og:url" content="http://cookbook.learndataengineering.com/docs/06-BestPracticesCloud"><link data-react-helmet="true" rel="shortcut icon" href="/images/CookbookCover.jpg"><link data-react-helmet="true" rel="alternate" href="http://cookbook.learndataengineering.com/docs/06-BestPracticesCloud" hreflang="x-default"><link data-react-helmet="true" rel="canonical" href="http://cookbook.learndataengineering.com/docs/06-BestPracticesCloud"><link rel="stylesheet" href="/assets/css/styles.5ba6ab3f.css">
<link rel="preload" href="/assets/js/styles.4aacfb65.js" as="script">
<link rel="preload" href="/assets/js/runtime~main.fda6c9fa.js" as="script">
<link rel="preload" href="/assets/js/main.4c5ae3c4.js" as="script">
<link rel="preload" href="/assets/js/1.4743d043.js" as="script">
<link rel="preload" href="/assets/js/2.d8ee9dd6.js" as="script">
<link rel="preload" href="/assets/js/18.28e25878.js" as="script">
<link rel="preload" href="/assets/js/19.f0bdf1f6.js" as="script">
<link rel="preload" href="/assets/js/935f2afb.cff03dc6.js" as="script">
<link rel="preload" href="/assets/js/17896441.aacbb830.js" as="script">
<link rel="preload" href="/assets/js/3fe089e3.5039dbf7.js" as="script">
</head>
<body>
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_1oUP">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img src="/images/CookbookCover.jpg" alt="Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/images/CookbookCover.jpg" alt="Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title">Data Engineering Cookbook</strong></a><a class="navbar__item navbar__link" href="/docs/01-Introduction">Cookbook</a></div><div class="navbar__items navbar__items--right"><a href="https://learndataengineering.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Data Engineering Academy</a><a href="https://medium.com/plumbersofdatascience" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Plumbers Of Data Science</a><a href="https://github.com/andkret/Cookbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img src="/images/CookbookCover.jpg" alt="Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/images/CookbookCover.jpg" alt="Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title">Data Engineering Cookbook</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/01-Introduction">Cookbook</a></li><li class="menu__list-item"><a href="https://learndataengineering.com/" target="_blank" rel="noopener noreferrer" class="menu__link">Data Engineering Academy</a></li><li class="menu__list-item"><a href="https://medium.com/plumbersofdatascience" target="_blank" rel="noopener noreferrer" class="menu__link">Plumbers Of Data Science</a></li><li class="menu__list-item"><a href="https://github.com/andkret/Cookbook" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_31aa"><div class="docSidebarContainer_3Kbt" role="complementary"><div class="sidebar_15mo"><div class="menu menu--responsive thin-scrollbar menu_Bmed"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Data Engineering</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/01-Introduction">01-Introduction</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/02-BasicSkills">02-BasicSkills</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/03-AdvancedSkills">03-AdvancedSkills</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/04-HandsOnCourse">04-HandsOnCourse</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/05-CaseStudies">05-CaseStudies</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/docs/06-BestPracticesCloud">06-BestPracticesCloud</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/07-DataSources">07-DataSources</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/08-InterviewQuestions">08-InterviewQuestions</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/09-BooksAndCourses">09-BooksAndCourses</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/10-Updates">10-Updates</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3ufF"><div class="container padding-vert--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><header><h1 class="docTitle_3a4h">06-BestPracticesCloud</h1></header><div class="markdown"><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="best-practices-cloud-platforms"></a>Best Practices Cloud Platforms<a class="hash-link" href="#best-practices-cloud-platforms" title="Direct link to heading">#</a></h1><p>This section is a collection of best practices on how you can arrange the tools together to a platform.<br>
It&#x27;s here especially to help you start your own project in the cloud on AWS, Azure and GCP.</p><p>Like the advanced skills section this section also follows my <a href="/docs/sections/01-Introduction.md#my-big-data-platform-blueprint">My Data Science Platform Blueprint</a>.
In the blueprint I divided the platform into sections: Connect, Buffer, Processing, Store and Visualize.</p><p>This order will help you learn how to connect the right tools together.
Take your time and research the tools and learn how they work.</p><p>Right now the Azure section has a lot of links to platform examples.
They are also useful for AWS and GCP, just try to change out the tools.</p><p>As always, I am going to add more stuff to this over time.</p><p>Have fun!</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="contents"></a>Contents<a class="hash-link" href="#contents" title="Direct link to heading">#</a></h2><ul><li><a href="/docs/06-BestPracticesCloud#aws">Amazon Web Services (AWS)</a><ul><li><a href="/docs/06-BestPracticesCloud#Connect">Connect</a></li><li><a href="/docs/06-BestPracticesCloud#Buffer">Buffer</a></li><li><a href="/docs/06-BestPracticesCloud#Processing">Processing</a></li><li><a href="/docs/06-BestPracticesCloud#Store">Store</a></li><li><a href="/docs/06-BestPracticesCloud#Visualize">Visualize</a></li><li><a href="/docs/06-BestPracticesCloud#Containerization">Containerization</a></li><li><a href="/docs/06-BestPracticesCloud#Best-Practices">Best Practices</a></li><li><a href="/docs/06-BestPracticesCloud#More-Details">More Details</a></li></ul></li><li><a href="/docs/06-BestPracticesCloud#azure">Microsoft Azure</a><ul><li><a href="/docs/06-BestPracticesCloud#Connect-1">Connect</a></li><li><a href="/docs/06-BestPracticesCloud#Buffer-1">Buffer</a></li><li><a href="/docs/06-BestPracticesCloud#Processing-1">Processing</a></li><li><a href="/docs/06-BestPracticesCloud#Store-1">Store</a></li><li><a href="/docs/06-BestPracticesCloud#Visualize-1">Visualize</a></li><li><a href="/docs/06-BestPracticesCloud#Containerization-1">Containerization</a></li><li><a href="/docs/06-BestPracticesCloud#Best-Practices-1">Best Practices</a></li></ul></li><li><a href="/docs/06-BestPracticesCloud#gcp">Google Cloud Platform (GCP)</a><ul><li><a href="/docs/06-BestPracticesCloud#Connect-2">Connect</a></li><li><a href="/docs/06-BestPracticesCloud#Buffer-2">Buffer</a></li><li><a href="/docs/06-BestPracticesCloud#Processing-2">Processing</a></li><li><a href="/docs/06-BestPracticesCloud#Store-2">Store</a></li><li><a href="/docs/06-BestPracticesCloud#Visualize-2">Visualize</a></li><li><a href="/docs/06-BestPracticesCloud#Containerization-2">Containerization</a></li><li><a href="/docs/06-BestPracticesCloud#Best-Practices-2">Best Practices</a></li></ul></li></ul><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="aws"></a>AWS<a class="hash-link" href="#aws" title="Direct link to heading">#</a></h1><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="connect"></a>Connect<a class="hash-link" href="#connect" title="Direct link to heading">#</a></h2><ul><li>Elastic Beanstalk (very old)</li><li>SES Simple Email Service</li><li>API Gateway</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="buffer"></a>Buffer<a class="hash-link" href="#buffer" title="Direct link to heading">#</a></h2><ul><li>Kinesis</li><li>Kinesis Data Firehose</li><li>Managed Streaming for Kafka (MSK)</li><li>MQ</li><li>Simple Queue Service (SQS)</li><li>Simple Notification Service (SNS)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="processing"></a>Processing<a class="hash-link" href="#processing" title="Direct link to heading">#</a></h2><ul><li>EC2</li><li>Athena</li><li>EMR</li><li>Elasticsearch</li><li>Kinesis Data Analytics</li><li>Glue</li><li>Step Functions</li><li>Fargate</li><li>Lambda</li><li>SageMaker</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="store"></a>Store<a class="hash-link" href="#store" title="Direct link to heading">#</a></h2><ul><li>Simple Storage Service (S3)</li><li>Redshift</li><li>Aurora</li><li>RDS</li><li>DynamoDB</li><li>ElastiCache</li><li>Neptune Graph DB</li><li>Timestream</li><li>DocumentDB (MongoDB compatible)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="visualize"></a>Visualize<a class="hash-link" href="#visualize" title="Direct link to heading">#</a></h2><ul><li>Quicksight</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="containerization"></a>Containerization<a class="hash-link" href="#containerization" title="Direct link to heading">#</a></h2><ul><li>Elastic Container Service (ECS)</li><li>Elastic Container Registry (ECR)</li><li>Elastic Kubernetes Service (EKS)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="best-practices"></a>Best Practices<a class="hash-link" href="#best-practices" title="Direct link to heading">#</a></h2><p>Deploying a Spring Boot Application on AWS Using AWS Elastic Beanstalk:</p><p><a href="https://aws.amazon.com/de/blogs/devops/deploying-a-spring-boot-application-on-aws-using-aws-elastic-beanstalk/" target="_blank" rel="noopener noreferrer">https://aws.amazon.com/de/blogs/devops/deploying-a-spring-boot-application-on-aws-using-aws-elastic-beanstalk/</a></p><p>How to deploy a Docker Container on AWS:</p><p><a href="https://aws.amazon.com/getting-started/hands-on/deploy-docker-containers/" target="_blank" rel="noopener noreferrer">https://aws.amazon.com/getting-started/hands-on/deploy-docker-containers/</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="aws-platform-architecture-for-genai"></a>AWS platform architecture for GenAI<a class="hash-link" href="#aws-platform-architecture-for-genai" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/genai-enterprise-bf79e003f8d44e5feab0e44999fd7907.png">
▶ <a href="https://youtu.be/2yX6G4ZURbc" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>I recorded a reaction video to an AWS platform architecture for GenAI called Tailwinds. Presented by John from Innovative Solutions and Josh from AWS, it has two main flows: indexing and consumer.</p><p>Data enters through S3 buckets or an API gateway, processed by AWS Lambda or Glue, and stored in a vector or graph database, then indexed in OpenSearch. Applications like chatbots use an API gateway to trigger Lambda functions for data retrieval and processing. This flexible serverless setup supports various data formats and uses tools like SAM and Terraform.</p><p>Amazon Bedrock helps customers choose and evaluate models. The architecture is flexible but requires effort to create the necessary Lambda functions. Check out the video and share your thoughts!</p><p>▶ <a href="https://youtu.be/2yX6G4ZURbc" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="generative-ai-enabled-job-search-engine"></a>Generative AI enabled job search engine<a class="hash-link" href="#generative-ai-enabled-job-search-engine" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/job-search-71ee8a92a46b382eacb0ae8180e443b7.png"></p><p>▶ <a href="https://youtu.be/dOWqasmqfHQ" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS platform architecture for a Gen AI job search engine. Presented by Andrea from AWS and Bill from Healthy Careers, this setup uses generative AI to enhance job searches for healthcare professionals.</p><p>The architecture uses Elastic Container Service (ECS) to handle user queries, processed by Claude II for prompt checks and geolocation. Cleaned prompts are vectorized using Amazon&#x27;s Titan model, with user search history fetched from an SQL database. Search results are stored in Elasticsearch, updating every six hours. Finally, Claude II generates a response from the search results and sends it back to the user.</p><p>I found the use of Claude II for prompt sanitization and geolocation, and the integration of multiple AI models through AWS Bedrock, particularly interesting. This setup keeps data private and provides a flexible, efficient job search experience.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="voice-transcription-and-analysis-on-aws"></a>Voice transcription and analysis on AWS<a class="hash-link" href="#voice-transcription-and-analysis-on-aws" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/voice-transcription-36e9b5d0eda7921d3efda6784ce48f75.png"></p><p>▶ <a href="https://youtu.be/RGXRjOTQuBM" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for voice transcription and analysis. Presented by Nuan from AWS and Ben from Assembly AI, this system is designed to handle large-scale audio data processing.</p><p>Users upload audio data via an API to an ECS container. The data is then managed by an orchestrator that decides which models to use and in what order. The orchestrator sends tasks to SQS, which triggers various ML models running on ECS. These models handle tasks like speech-to-text conversion, sentiment analysis, and speaker labeling. Results are stored in S3 and users are notified via SNS and a Lambda function when processing is complete.</p><p>I found the use of ECS for containerized applications and the flexibility of swapping models through ECR particularly interesting. This architecture ensures scalability and efficiency, making it ideal for handling millions of requests per day.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="geospatial-data-analysis"></a>GeoSpatial Data Analysis<a class="hash-link" href="#geospatial-data-analysis" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/geo-spacial-9a602f542c5c0b803268c0a1218d3a61.png"></p><p>▶ <a href="https://youtu.be/MxVJAvFSTXg" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for geospatial data analysis by TCS. Presented by David John and Suryakant from TCS, this platform is used in next-gen agriculture for tasks like crop health, yield, and soil moisture analysis.</p><p>The platform uses data from satellites, AWS open data, and field agents, processing it with Lambda, Sagemaker, and PostgreSQL. Data is stored and analyzed in S3 buckets and PostgreSQL, with results made accessible via EKS-deployed UIs on EC2 instances, buffered through CloudFront for efficiency.</p><p>Key aspects include:</p><ul><li>Lambda functions triggering Sagemaker jobs for machine learning.</li><li>Sagemaker handling extensive processing tasks.</li><li>PostgreSQL and S3 for storing processed data.</li><li>CloudFront caching data to enhance user experience.</li><li>I found the use of parallel Sagemaker jobs for scalability and the integration of open data for cost efficiency particularly interesting. This setup effectively meets the agricultural sector&#x27;s data analysis needs.</li></ul><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="building-a-self-service-enterprise-data-engineering-platform"></a>Building a Self-Service Enterprise Data Engineering Platform<a class="hash-link" href="#building-a-self-service-enterprise-data-engineering-platform" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/enterprise-solution-0962f5f3190a6ebf7433f8e46988360e.png"></p><p>▶ <a href="https://youtu.be/E9JFCl7bk88" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for a self-service enterprise data engineering platform by ZS Associates. Presented by David John and Laken from ZS Associates, this platform is designed to streamline data integration, infrastructure provisioning, and data access for life sciences companies.</p><p>Key components:</p><ul><li><strong>Users and Interaction</strong>: Data engineers and analysts interact through a self-service web portal, selecting infrastructure types and providing project details. This portal makes REST requests to EKS, which creates records in PostgreSQL and triggers infrastructure provisioning via SQS.</li><li><strong>Infrastructure Provisioning</strong>: EKS processes SQS messages to provision infrastructure such as EMR clusters, databases in Glue Catalog, S3 buckets, and EC2 instances with containerized services like Airflow or NiFi. IAM roles are configured for access control.</li><li><strong>Data Governance and Security</strong>: All data sets are accessed through the Glue Catalog, with governance workflows requiring approval from data owners via SES notifications. EKS updates IAM roles and Ranger policies for fine-grained access control.</li><li><strong>Scalability and Efficiency</strong>: EKS hosts 100+ microservices supporting workflows and UI portals. The platform handles millions of API requests and hundreds of data access requests monthly, with auto-scaling capabilities to manage costs.</li></ul><p>This architecture effectively reduces time to market, enhances security at scale, and optimizes costs by automating data access and infrastructure provisioning. It also ensures data governance and security through controlled access and approval processes.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="customer-support-platform"></a>Customer Support Platform<a class="hash-link" href="#customer-support-platform" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/customer-support-cb6705d1e89738592f41f29603c961f6.png"></p><p>▶ <a href="https://youtu.be/sCIFpOuryFU" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for a personalized customer support platform by Traeger. Presented by David John and Lizzy from Traeger, this system enhances customer support by leveraging data from Shopify, EventBridge, Kinesis Data Firehose, S3, Lambda, DynamoDB, and Amazon Connect.</p><p>Key components:</p><ul><li><strong>Order Processing</strong>: Customer order data from Shopify flows into EventBridge, then to Kinesis Data Firehose, which writes it to S3. An event trigger in S3 invokes a Lambda function that stores specific order metadata in DynamoDB.</li><li><strong>Personalized Customer Support</strong>: When a customer calls, Amazon Connect uses Pinpoint to determine the call&#x27;s origin, personalizing the language options. Connect triggers a Lambda function to query DynamoDB for customer metadata based on the phone number. This data is used to inform the customer support agent.</li><li><strong>Reason for Contact</strong>: Amazon Lex bot asks the customer the reason for their call, and this information, along with customer metadata, routes the call to a specialized support queue.</li></ul><p>I found the use of DynamoDB for storing customer metadata and the integration with Amazon Connect and Lex for personalized support particularly interesting. The architecture is scalable and ensures a personalized experience for customers.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="league-of-legends-data-platform-on-aws"></a>League of Legends Data Platform on AWS<a class="hash-link" href="#league-of-legends-data-platform-on-aws" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/league-c90677d5e78008d1a4b90fa9fc53388c.jpg"></p><p>▶ <a href="https://youtu.be/FX_ZUJk_WoE" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for the data platform that powers League of Legends by Riot Games. Presented by David John and the team at Riot Games, this system handles massive amounts of data generated by millions of players worldwide.</p><p>Key components:</p><ul><li><strong>Player Interaction</strong>: Players connect to game servers globally. The game client communicates with an API running in EKS. This setup ensures low latency and optimal performance.</li><li><strong>Data Ingestion</strong>: The game client and server send data about player interactions to EKS, which flows into MSK (Managed Streaming for Kafka). Local Kafka clusters buffer the data before it’s replicated to regional MSK clusters using MirrorMaker.</li><li><strong>Data Processing</strong>: Spark Streaming jobs process the data from MSK and store it in Delta Lake on S3. This setup ensures efficient data handling and reduces latency in data availability.</li><li><strong>Data Storage and Access</strong>: Glue serves as the data catalog, managing metadata and permissions. Data consumers, including analysts, designers, engineers, and executives, access this data through Databricks, leveraging Glue for structured queries.</li></ul><p>I found the use of MSK and Spark for scalable data ingestion and processing particularly interesting. This architecture supports real-time analytics, allowing Riot Games to quickly assess the impact of new patches and gameplay changes.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="platform-connecting-70-million-cars"></a>Platform Connecting 70 Million Cars<a class="hash-link" href="#platform-connecting-70-million-cars" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/70m-cars-154036961a94497952e067432c0384b1.png"></p><p>▶ <a href="https://youtu.be/1nifzmvOGHs" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for a connected car platform by Mobileye. Presented by David John and the team at Mobileye, this system connects 70 million cars, collecting and processing data to offer digital services and fleet analysis.</p><p>Key components:</p><ul><li><strong>Data Collection</strong>: Cars collect anonymized data using sensors and visual inspections, sending it to a REST API and storing it in S3.</li><li><strong>Data Processing</strong>: The data is pulled from S3 into SQS and processed by EKS workers, which scale according to the queue size. Processed data is stored back in S3 and further analyzed using step functions and Lambda for tasks like extracting construction zones and clustering observations.</li><li><strong>Data Storage</strong>: Processed data is stored in S3, Elasticsearch, and CockroachDB. Elasticsearch handles document-based data with self-indexing, while CockroachDB supports frequent updates.</li><li><strong>Data Consumption</strong>: EKS hosts a secured REST API and web application, allowing customers like city planners to access insights on pedestrian and bicycle traffic.</li></ul><p>Future plans include enabling cloud image processing on EKS with GPU instances and focusing on cost reduction as data flow increases.</p><p>I found the use of EKS for scalable data processing and the combination of Elasticsearch and CockroachDB for different data needs particularly interesting. This architecture efficiently handles large-scale data from millions of connected cars.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="55tb-a-day-nielsen-aws-data-architecture"></a>55TB A Day: Nielsen AWS Data Architecture<a class="hash-link" href="#55tb-a-day-nielsen-aws-data-architecture" title="Direct link to heading">#</a></h4><p><img alt="Imagetitle" src="/assets/images/55-tb-9acce6d6992738efa480500925295d79.png"></p><p>▶ <a href="https://youtu.be/WCQe1VP_q5A" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey everyone, I recorded a reaction video to an AWS architecture for Nielsen Marketing Cloud, which processes 55TB of data daily. Presented by David John, this system handles marketing segmentation data for campaigns.</p><p>Key components:</p><ul><li><strong>Data Ingestion</strong>: Marketing data comes in files, written to S3. Spark on EMR processes and transforms the data, writing the output to another S3 bucket.</li><li><strong>Data Processing</strong>: Lambda functions handle the final formatting and upload the data to over 100 ad networks. Metadata about file processing is managed in a PostgreSQL RDS database.</li><li><strong>Metadata Management</strong>: A work manager Lambda reads metadata from RDS, triggers processing jobs in EMR, and updates the metadata post-processing.</li><li><strong>Scaling and Rate Limiting</strong>: The serverless architecture allows automatic scaling. However, rate limiting is implemented to prevent overloading ad networks, ensuring they handle data bursts smoothly.</li></ul><p>Challenges and Solutions:</p><ul><li><strong>Scale</strong>: The system handles 250 billion events per day, scaling up and down automatically to manage peak loads.</li><li><strong>Rate Limiting</strong>: To avoid overwhelming ad networks, a rate-limiting mechanism was introduced, managing data flow based on network capacity.</li><li><strong>Back Pressure Management</strong>: SQS is used to buffer Lambda responses, preventing direct overload on the PostgreSQL database.</li></ul><p>I found the use of SQS for metadata management and the serverless architecture for handling massive data loads particularly interesting. This setup ensures efficient data processing and smooth delivery to ad networks.</p><p>Check out the video and share your thoughts!</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="orange-theory-fitness"></a>Orange Theory Fitness<a class="hash-link" href="#orange-theory-fitness" title="Direct link to heading">#</a></h4><p><img alt="Image" src="/assets/images/fitness-1-c8c166aad92b24e34e1b3d89cd258691.jpeg"></p><p>▶ <a href="https://youtu.be/ssaXRo5s1r4" target="_blank" rel="noopener noreferrer">Click here to watch</a></p><p>Hey, everybody! Today, I&#x27;m reacting to the AWS data infrastructure at Orange Theory Fitness, where they collect data from wristbands and training machines. Let&#x27;s dive in and see how they manage it all.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="key-components"></a>Key Components<a class="hash-link" href="#key-components" title="Direct link to heading">#</a></h3><ol><li><strong>Local Server</strong>: Aggregates data from in-studio equipment and mobile apps, ensuring resiliency if the cloud connection is lost.</li><li><strong>API Gateway and Cognito</strong>: Handle authentication and route data to the cloud.</li><li><strong>Lambda Functions</strong>: Process data.</li><li><strong>Aurora RDS (MySQL)</strong>: Stores structured data like member profiles, class bookings, and studio information.</li><li><strong>DynamoDB</strong>: Stores performance metrics and workout statistics for quick access.</li><li><strong>S3</strong>: Serves as a data lake, storing telemetry data.</li><li><strong>Kinesis Firehose</strong>: Streams telemetry data to S3.</li></ol><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="challenges--solutions"></a>Challenges &amp; Solutions<a class="hash-link" href="#challenges--solutions" title="Direct link to heading">#</a></h3><ol><li><p><strong>Resiliency</strong></p><ul><li><strong>Challenge</strong>: Ensure operations continue if cloud connection is lost.</li><li><strong>Solution</strong>: Local server aggregates data and syncs with the cloud once the connection is restored.</li></ul></li><li><p><strong>Data Integration</strong></p><ul><li><strong>Challenge</strong>: Integrate data from various sources.</li><li><strong>Solution</strong>: Use API Gateway and Cognito for unified authentication and data routing.</li></ul></li><li><p><strong>Data Processing</strong></p><ul><li><strong>Challenge</strong>: Efficiently process and store different types of data.</li><li><strong>Solution</strong>: Use Lambda for processing, Aurora RDS for structured data, DynamoDB for quick access to performance metrics, and Kinesis Firehose with S3 for streaming and storing large volumes of telemetry data.</li></ul></li></ol><p>This architecture leverages AWS tools for scalability, flexibility, and resilience, making it an excellent example of a well-thought-out data infrastructure for a fitness application.</p><p>Let me know your thoughts in the comments. What do you think of this architecture? Would you have done anything differently? If you have any questions, feel free to ask. And if you&#x27;re interested in learning more about data engineering, check out my academy at learndataengineering.com. See you in the next video!</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="more-details"></a>More Details<a class="hash-link" href="#more-details" title="Direct link to heading">#</a></h2><p>AWS Whitepapers:</p><p><a href="https://d1.awsstatic.com/whitepapers/aws-overview.pdf" target="_blank" rel="noopener noreferrer">https://d1.awsstatic.com/whitepapers/aws-overview.pdf</a></p><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="azure"></a>Azure<a class="hash-link" href="#azure" title="Direct link to heading">#</a></h1><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="connect-1"></a>Connect<a class="hash-link" href="#connect-1" title="Direct link to heading">#</a></h2><ul><li>Event Hub</li><li>IoT Hub</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="buffer-1"></a>Buffer<a class="hash-link" href="#buffer-1" title="Direct link to heading">#</a></h2><ul><li>Data Factory</li><li>Event Hub</li><li>RedisCache (also Store)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="processing-1"></a>Processing<a class="hash-link" href="#processing-1" title="Direct link to heading">#</a></h2><ul><li>Stream Analytics Service</li><li>Azure Databricks</li><li>Machine Learning</li><li>Azure Functions</li><li>Azure HDInsight (Hadoop PaaS)</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="store-1"></a>Store<a class="hash-link" href="#store-1" title="Direct link to heading">#</a></h2><ul><li>Blob</li><li>CosmosDB</li><li>MariaDB</li><li>MySQL</li><li>PostgreSQL</li><li>SQL</li><li>Azure Data lake</li><li>Azure Storage (SQL Table?)</li><li>Azure Synapse Analytics</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="visualize-1"></a>Visualize<a class="hash-link" href="#visualize-1" title="Direct link to heading">#</a></h2><ul><li>PowerBI</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="containerization-1"></a>Containerization<a class="hash-link" href="#containerization-1" title="Direct link to heading">#</a></h2><ul><li>Virtual Machines</li><li>Virtual Machine Scale Sets</li><li>Azure Container Service (AKS)</li><li>Container Instances</li><li>Azure Kubernetes Service</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="best-practices-1"></a>Best Practices<a class="hash-link" href="#best-practices-1" title="Direct link to heading">#</a></h2><p>Advanced Analytics Architecture:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/advanced-analytics-on-big-data" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/advanced-analytics-on-big-data</a></p><p>Anomaly Detection in Real-time Data Streams:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/anomaly-detection-in-real-time-data-streams" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/anomaly-detection-in-real-time-data-streams</a></p><p>Modern Data Warehouse Architecture:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/modern-data-warehouse" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/modern-data-warehouse</a></p><p>CI/CD for Containers:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/cicd-for-containers" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/cicd-for-containers</a></p><p>Real Time Analytics on Big Data Architecture:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/real-time-analytics" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/real-time-analytics</a></p><p>Anomaly Detection in Real-time Data Streams:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/anomaly-detection-in-real-time-data-streams" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/anomaly-detection-in-real-time-data-streams</a></p><p>IoT Architecture – Azure IoT Subsystems:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/azure-iot-subsystems" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/azure-iot-subsystems</a></p><p>Tier Applications &amp; Data for Analytics:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/tiered-data-for-analytics" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/tiered-data-for-analytics</a></p><p>Extract, transform, and load (ETL) using HDInsight:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/extract-transform-and-load-using-hdinsight" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/extract-transform-and-load-using-hdinsight</a></p><p>IoT using Cosmos DB:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/iot-using-cosmos-db" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/iot-using-cosmos-db</a></p><p>Streaming using HDInsight:</p><p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/streaming-using-hdinsight" target="_blank" rel="noopener noreferrer">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/streaming-using-hdinsight</a></p><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="gcp"></a>GCP<a class="hash-link" href="#gcp" title="Direct link to heading">#</a></h1><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="connect-2"></a>Connect<a class="hash-link" href="#connect-2" title="Direct link to heading">#</a></h2><ul><li>Cloud IoT Core</li><li>App Engine</li><li>Cloud Dataflow</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="buffer-2"></a>Buffer<a class="hash-link" href="#buffer-2" title="Direct link to heading">#</a></h2><ul><li>Pub/Sub</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="processing-2"></a>Processing<a class="hash-link" href="#processing-2" title="Direct link to heading">#</a></h2><ul><li>Compute Engine</li><li>Cloud Functions</li><li>Specialized tools:<ul><li>Cloud Dataflow</li><li>Cloud Dataproc</li><li>Cloud Datalab</li><li>Cloud Dataprep</li><li>Cloud Composer</li></ul></li><li>App Engine</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="store-2"></a>Store<a class="hash-link" href="#store-2" title="Direct link to heading">#</a></h2><ul><li>Cloud Storage</li><li>Cloud SQL</li><li>Cloud Spanner</li><li>Cloud Datastore</li><li>Cloud BigTable</li><li>Cloud Storage</li><li>Cloud Memorystore</li><li>BigQuery</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="visualize-2"></a>Visualize<a class="hash-link" href="#visualize-2" title="Direct link to heading">#</a></h2><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="containerization-2"></a>Containerization<a class="hash-link" href="#containerization-2" title="Direct link to heading">#</a></h2><ul><li>Kubernetes Engine</li><li>Container Security</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="best-practices-2"></a>Best Practices<a class="hash-link" href="#best-practices-2" title="Direct link to heading">#</a></h2><p>Thanks to Ismail Holoubi for the following GCP links</p><p>Best practices for migrating virtual machines to Compute Engine:</p><p><a href="https://cloud.google.com/solutions/best-practices-migrating-vm-to-compute-engine" target="_blank" rel="noopener noreferrer">https://cloud.google.com/solutions/best-practices-migrating-vm-to-compute-engine</a></p><p>Best practices for Cloud Storage:</p><p><a href="https://cloud.google.com/storage/docs/best-practices" target="_blank" rel="noopener noreferrer">https://cloud.google.com/storage/docs/best-practices</a></p><p>Moving a publishing workflow to BigQuery for new data insights:</p><p><a href="https://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights" target="_blank" rel="noopener noreferrer">https://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights</a></p><p>Architecture: Optimizing large-scale ingestion of analytics events and logs:</p><p><a href="https://cloud.google.com/solutions/architecture/optimized-large-scale-analytics-ingestion" target="_blank" rel="noopener noreferrer">https://cloud.google.com/solutions/architecture/optimized-large-scale-analytics-ingestion</a></p><p>Choosing the right architecture for global data distribution:</p><p><a href="https://cloud.google.com/solutions/architecture/global-data-distribution" target="_blank" rel="noopener noreferrer">https://cloud.google.com/solutions/architecture/global-data-distribution</a></p><p>Best Practices for Operating Containers:</p><p><a href="https://cloud.google.com/solutions/best-practices-for-operating-containers" target="_blank" rel="noopener noreferrer">https://cloud.google.com/solutions/best-practices-for-operating-containers</a></p><p>Automating IoT Machine Learning: Bridging Cloud and Device Benefits with AI Platform:</p><p><a href="https://cloud.google.com/solutions/automating-iot-machine-learning" target="_blank" rel="noopener noreferrer">https://cloud.google.com/solutions/automating-iot-machine-learning</a></p></div></article><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/05-CaseStudies"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« 05-CaseStudies</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/07-DataSources"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">07-DataSources »</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#contents" class="table-of-contents__link">Contents</a></li><li><a href="#connect" class="table-of-contents__link">Connect</a></li><li><a href="#buffer" class="table-of-contents__link">Buffer</a></li><li><a href="#processing" class="table-of-contents__link">Processing</a></li><li><a href="#store" class="table-of-contents__link">Store</a></li><li><a href="#visualize" class="table-of-contents__link">Visualize</a></li><li><a href="#containerization" class="table-of-contents__link">Containerization</a></li><li><a href="#best-practices" class="table-of-contents__link">Best Practices</a><ul><li><a href="#key-components" class="table-of-contents__link">Key Components</a></li><li><a href="#challenges--solutions" class="table-of-contents__link">Challenges &amp; Solutions</a></li></ul></li><li><a href="#more-details" class="table-of-contents__link">More Details</a></li><li><a href="#connect-1" class="table-of-contents__link">Connect</a></li><li><a href="#buffer-1" class="table-of-contents__link">Buffer</a></li><li><a href="#processing-1" class="table-of-contents__link">Processing</a></li><li><a href="#store-1" class="table-of-contents__link">Store</a></li><li><a href="#visualize-1" class="table-of-contents__link">Visualize</a></li><li><a href="#containerization-1" class="table-of-contents__link">Containerization</a></li><li><a href="#best-practices-1" class="table-of-contents__link">Best Practices</a></li><li><a href="#connect-2" class="table-of-contents__link">Connect</a></li><li><a href="#buffer-2" class="table-of-contents__link">Buffer</a></li><li><a href="#processing-2" class="table-of-contents__link">Processing</a></li><li><a href="#store-2" class="table-of-contents__link">Store</a></li><li><a href="#visualize-2" class="table-of-contents__link">Visualize</a></li><li><a href="#containerization-2" class="table-of-contents__link">Containerization</a></li><li><a href="#best-practices-2" class="table-of-contents__link">Best Practices</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Andreas Kretz. Built by Kristijan Bakaric with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/styles.4aacfb65.js"></script>
<script src="/assets/js/runtime~main.fda6c9fa.js"></script>
<script src="/assets/js/main.4c5ae3c4.js"></script>
<script src="/assets/js/1.4743d043.js"></script>
<script src="/assets/js/2.d8ee9dd6.js"></script>
<script src="/assets/js/18.28e25878.js"></script>
<script src="/assets/js/19.f0bdf1f6.js"></script>
<script src="/assets/js/935f2afb.cff03dc6.js"></script>
<script src="/assets/js/17896441.aacbb830.js"></script>
<script src="/assets/js/3fe089e3.5039dbf7.js"></script>
</body>
</html>